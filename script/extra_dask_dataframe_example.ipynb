{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "192a0864",
   "metadata": {},
   "source": [
    "# Extra Example: Parquet Data with Intake Catalog\n",
    "\n",
    "This notebook demonstrates the basic workflow of loading tabular data (Parquet format) using Intake catalogs.\n",
    "\n",
    "## Key Learning Points:\n",
    "\n",
    "1. **Loading Parquet data through Intake catalogs**\n",
    "2. **Basic difference between Pandas and Dask DataFrames**\n",
    "3. **When to use Dask for larger datasets**\n",
    "\n",
    "## Important Notes:\n",
    "\n",
    "- Intake provides unified access to different data formats\n",
    "- Pandas DataFrames: Load entire dataset into memory\n",
    "- Dask DataFrames: Lazy loading, suitable for large datasets\n",
    "- Both can be accessed through the same catalog interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31f05b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "\n",
    "# Load catalog\n",
    "catalog = intake.open_catalog('../catalogs/station_intake_catalog.yaml')\n",
    "\n",
    "# Explore available datasets\n",
    "print(\"üìÅ Available datasets:\")\n",
    "for name in catalog:\n",
    "    print(f\"  ‚Ä¢ {name}\")\n",
    "\n",
    "print(f\"\\nüìä Total datasets: {len(list(catalog))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd045c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Load as Pandas DataFrame (loads entire dataset into memory)\n",
    "print(\"Loading data as Pandas DataFrame...\")\n",
    "df = catalog.nyc_taxi_sample.read()\n",
    "\n",
    "print(f\"\\nDataset Information:\")\n",
    "print(f\"- Shape: {df.shape}\")\n",
    "print(f\"- Total rows: {len(df):,}\")\n",
    "print(f\"- Total columns: {len(df.columns)}\")\n",
    "print(f\"- Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "\n",
    "# Show first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9345ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Load as Dask DataFrame (lazy loading for larger datasets)\n",
    "print(\"Loading data as Dask DataFrame...\")\n",
    "ddf = catalog.nyc_taxi_sample.to_dask()\n",
    "\n",
    "print(f\"\\nDataset Information:\")\n",
    "print(f\"- Number of partitions: {ddf.npartitions}\")\n",
    "print(f\"- Total columns: {len(ddf.columns)}\")\n",
    "print(f\"- Estimated memory usage: {ddf.memory_usage(deep=True).sum().compute() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(f\"\\nColumns: {list(ddf.columns)}\")\n",
    "\n",
    "# Show first few rows (this triggers computation)\n",
    "print(\"\\nFirst 5 ros:\")\n",
    "ddf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbbb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìã Comparison Summary\n",
    "print(\"=\" * 60)\n",
    "print(\"PANDAS vs DASK DATAFRAME COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nPandas DataFrame:\")\n",
    "print(f\"   ‚Ä¢ Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"   ‚Ä¢ Loading: All data loaded into memory immediately\")\n",
    "print(f\"   ‚Ä¢ Operations: Immediate execution\")\n",
    "print(f\"   ‚Ä¢ Best for: Small to medium datasets\")\n",
    "\n",
    "print(\"\\nDask DataFrame:\")\n",
    "print(f\"   ‚Ä¢ Partitions: {ddf.npartitions}\")\n",
    "print(f\"   ‚Ä¢ Loading: Lazy evaluation (operations planned, not executed)\")\n",
    "print(f\"   ‚Ä¢ Operations: Execute with .compute()\")\n",
    "print(f\"   ‚Ä¢ Best for: Large datasets that don't fit in memory\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ Both methods access the same data through Intake catalog!\")\n",
    "print(\"üí° Choose based on your dataset size and memory constraints.\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset-catalog-workshop",
   "language": "python",
   "name": "dataset-catalog-workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
